{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "silver-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_data_ingestion import ingest_stocks_to_df\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "from keras.layers import LSTM, Dense, Input, Dropout, Activation, BatchNormalization, LayerNormalization, GRU, Bidirectional\n",
    "from keras import Sequential\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.losses import MeanSquaredError\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.activations import relu\n",
    "from keras.callbacks import EarlyStopping\n",
    "from preprocessing_ts_keras_finance import to_ts_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-thompson",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "uniform-precipitation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-03-02</th>\n",
       "      <td>5.770000</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.770000</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>5.770000</td>\n",
       "      <td>GSIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>20300.0</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>GSIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-04</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.780000</td>\n",
       "      <td>5.760000</td>\n",
       "      <td>24300.0</td>\n",
       "      <td>5.760000</td>\n",
       "      <td>GSIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-05</th>\n",
       "      <td>5.850000</td>\n",
       "      <td>5.790000</td>\n",
       "      <td>5.790000</td>\n",
       "      <td>5.840000</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>5.840000</td>\n",
       "      <td>GSIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-06</th>\n",
       "      <td>5.850000</td>\n",
       "      <td>5.580000</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>5.830000</td>\n",
       "      <td>19200.0</td>\n",
       "      <td>5.830000</td>\n",
       "      <td>GSIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22</th>\n",
       "      <td>182.440002</td>\n",
       "      <td>175.059998</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>175.289993</td>\n",
       "      <td>2661300.0</td>\n",
       "      <td>175.289993</td>\n",
       "      <td>ARKW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-23</th>\n",
       "      <td>170.748993</td>\n",
       "      <td>156.880005</td>\n",
       "      <td>165.570007</td>\n",
       "      <td>170.160004</td>\n",
       "      <td>6246800.0</td>\n",
       "      <td>170.160004</td>\n",
       "      <td>ARKW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-24</th>\n",
       "      <td>171.776001</td>\n",
       "      <td>165.910004</td>\n",
       "      <td>169.100006</td>\n",
       "      <td>170.539993</td>\n",
       "      <td>2394900.0</td>\n",
       "      <td>170.539993</td>\n",
       "      <td>ARKW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-25</th>\n",
       "      <td>171.509995</td>\n",
       "      <td>158.919998</td>\n",
       "      <td>168.910004</td>\n",
       "      <td>160.259995</td>\n",
       "      <td>3364400.0</td>\n",
       "      <td>160.259995</td>\n",
       "      <td>ARKW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-26</th>\n",
       "      <td>163.559998</td>\n",
       "      <td>155.949997</td>\n",
       "      <td>161.020004</td>\n",
       "      <td>160.889999</td>\n",
       "      <td>2701300.0</td>\n",
       "      <td>160.889999</td>\n",
       "      <td>ARKW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7424 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close     Volume  \\\n",
       "Date                                                                    \n",
       "2015-03-02    5.770000    5.680000    5.700000    5.770000     8400.0   \n",
       "2015-03-03    5.800000    5.750000    5.750000    5.800000    20300.0   \n",
       "2015-03-04    5.800000    5.700000    5.780000    5.760000    24300.0   \n",
       "2015-03-05    5.850000    5.790000    5.790000    5.840000    15900.0   \n",
       "2015-03-06    5.850000    5.580000    5.850000    5.830000    19200.0   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2021-02-22  182.440002  175.059998  181.000000  175.289993  2661300.0   \n",
       "2021-02-23  170.748993  156.880005  165.570007  170.160004  6246800.0   \n",
       "2021-02-24  171.776001  165.910004  169.100006  170.539993  2394900.0   \n",
       "2021-02-25  171.509995  158.919998  168.910004  160.259995  3364400.0   \n",
       "2021-02-26  163.559998  155.949997  161.020004  160.889999  2701300.0   \n",
       "\n",
       "             Adj Close company_name  \n",
       "Date                                 \n",
       "2015-03-02    5.770000         GSIT  \n",
       "2015-03-03    5.800000         GSIT  \n",
       "2015-03-04    5.760000         GSIT  \n",
       "2015-03-05    5.840000         GSIT  \n",
       "2015-03-06    5.830000         GSIT  \n",
       "...                ...          ...  \n",
       "2021-02-22  175.289993         ARKW  \n",
       "2021-02-23  170.160004         ARKW  \n",
       "2021-02-24  170.539993         ARKW  \n",
       "2021-02-25  160.259995         ARKW  \n",
       "2021-02-26  160.889999         ARKW  \n",
       "\n",
       "[7424 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSIT len 1510\n",
      "ICAD len 1510\n",
      "XAIR len 683\n",
      "LTRN len 180\n",
      "ARKK len 1510\n",
      "ARKF len 521\n",
      "ARKW len 1510\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.sequence.TimeseriesGenerator at 0x7ff2446a4670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comment first line out after first use to prevent \n",
    "# giving the source website for the stocks too much traffic. \n",
    "stocks_df = ingest_stocks_to_df()\n",
    "stock_list = stocks_df.company_name.unique()\n",
    "# displays\n",
    "display(stocks_df)\n",
    "for stock in stock_list:\n",
    "    print(stock, 'len', len(stocks_df[stocks_df.company_name == stock].index))\n",
    "sns.lineplot(x=stocks_df.index, y='Adj Close',data=stocks_df, legend='auto', hue='company_name')\n",
    "plt.show()\n",
    "data_gen_train, data_gen_test = to_ts_data(stock_list[0], stocks_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-sustainability",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "nutritional-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout)\n",
    "    model = Sequential()\n",
    "#     model.add(Input((1,1)))\n",
    "    model.add(lstm_layer)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def seq_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout, return_sequences=True)\n",
    "    model = Sequential()\n",
    "    model.add(lstm_layer)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def bi_seq_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout, return_sequences=True)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(lstm_layer))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def stack_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, dropout=dropout, recurrent_dropout=recurrent_dropout, return_sequences=True)\n",
    "    model = Sequential()\n",
    "    model.add(lstm_layer)\n",
    "    model.add(lstm_layer)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def bi_stack_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout, return_sequences=True)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(lstm_layer))\n",
    "    model.add(Bidirectional(lstm_layer))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def bi_back_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout, return_sequences=True)\n",
    "    model = Sequential()\n",
    "    forward_layer = LSTM(nodes_lstm, return_sequences=True)\n",
    "    backward_layer = LSTM(nodes_lstm, return_sequences=True,\n",
    "                       go_backwards=True)\n",
    "    model.add(Bidirectional(forward_layer, backward_layer=backward_layer))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def bi_back_stack_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    ## TODO: figure out how to have first bi pass sequence to second. \n",
    "    model = Sequential()\n",
    "    forward_layer = LSTM(nodes_lstm, return_sequences=True)\n",
    "    backward_layer = LSTM(nodes_lstm, return_sequences=True, go_backwards=True)\n",
    "    model.add(Bidirectional(forward_layer, backward_layer=backward_layer, return_sequences=True))\n",
    "    model.add(Bidirectional(forward_layer, backward_layer=backward_layer))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def stack_3_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, dropout=dropout, recurrent_dropout=recurrent_dropout, return_sequences=True)\n",
    "    model = Sequential()\n",
    "    model.add(lstm_layer)\n",
    "    model.add(lstm_layer)\n",
    "    model.add(lstm_layer)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def deep_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout)\n",
    "    model = Sequential()\n",
    "#     model.add(Input((1,1)))\n",
    "    model.add(lstm_layer)\n",
    "    model.add(Dense(32))    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(32))    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def deep_lstm_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout)\n",
    "    model = Sequential()\n",
    "#     model.add(Input((1,1)))\n",
    "    model.add(lstm_layer)\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(32))    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(32))    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(32))    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def lstm_dense_model(nodes_lstm=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, dropout=dropout, recurrent_dropout=recurrent_dropout)\n",
    "    model = Sequential()\n",
    "#     model.add(Input((1,1)))\n",
    "    model.add(lstm_layer)\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def batch_norm_lstm_model(nodes_lstm=50, dropout=0.5, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout)\n",
    "    model = Sequential()\n",
    "#     model.add(Input((1,1)))\n",
    "    model.add(lstm_layer)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def layer_norm_lstm_model(nodes_lstm=50, dropout=0.5, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout)\n",
    "    model = Sequential()\n",
    "#     model.add(Input((1,1)))\n",
    "    model.add(lstm_layer)\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(32))    \n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "# lstm_model().summary()\n",
    "def batch_norm_drop_lstm_model(nodes_lstm=50, dropout=0.5, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    lstm_layer = LSTM(nodes_lstm, recurrent_dropout=recurrent_dropout)\n",
    "    model = Sequential()\n",
    "#     model.add(Input((1,1)))\n",
    "    model.add(lstm_layer)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(32))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "def gru_model(nodes=50, dropout=0.0, recurrent_dropout=0.0, learning_rate=0.01, loss='mse', optimizer=Adam, metrics=['mse']):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(nodes))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-tokyo",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equipped-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indirect-nutrition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 3s 58ms/step - loss: 25.6235 - mse: 25.6235\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 3.7571 - mse: 3.7571\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 2.8620 - mse: 2.8620\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 3.4331 - mse: 3.4331\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 2.9243 - mse: 2.9243\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 2.7094 - mse: 2.7094\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 2.9750 - mse: 2.9750\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 3.2854 - mse: 3.2854\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 2.6005 - mse: 2.6005\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 2.3208 - mse: 2.3208\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 2.1895 - mse: 2.1895\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2.2083 - mse: 2.2083\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 2.4189 - mse: 2.4189\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1.9736 - mse: 1.9736\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 2.6966 - mse: 2.6966\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 1s 53ms/step - loss: 2.4105 - mse: 2.4105\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 2.5769 - mse: 2.5769\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 2.5957 - mse: 2.5957\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 2.7139 - mse: 2.7139\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 2.1349 - mse: 2.1349\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 2.1794 - mse: 2.1794\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50)                22200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 22,251\n",
      "Trainable params: 22,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5875 - mse: 0.5875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5875466465950012, 0.5875466465950012]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "raised-prophet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 3s 58ms/step - loss: 20.2998 - mse: 20.2998\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 3.5877 - mse: 3.5877\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 3.0653 - mse: 3.0653\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 4.1344 - mse: 4.1344\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 3.3311 - mse: 3.3311\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1.9100 - mse: 1.9100\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.9188 - mse: 2.9188\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.9556 - mse: 2.9556\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 2.9374 - mse: 2.9374\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 3.1937 - mse: 3.1937\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 1s 54ms/step - loss: 2.3402 - mse: 2.3402\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.2046 - mse: 3.2046\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.7077 - mse: 2.7077\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 3.5208 - mse: 3.5208\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 3.5060 - mse: 3.5060\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.4949 - mse: 2.4949\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 2.5763 - mse: 2.5763\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1.9532 - mse: 1.9532\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1.7651 - mse: 1.7651\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.3342 - mse: 2.3342\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 2.6806 - mse: 2.6806\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 3.4591 - mse: 3.4591\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.9072 - mse: 2.9072\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 2.1697 - mse: 2.1697\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 50)          22200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1)           51        \n",
      "=================================================================\n",
      "Total params: 22,251\n",
      "Trainable params: 22,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 19ms/step - loss: 0.5916 - mse: 0.5916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5916388630867004, 0.5916388630867004]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = seq_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "statistical-mentor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 4s 75ms/step - loss: 20.3353 - mse: 20.3353\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 2.3442 - mse: 2.3442\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 2.5781 - mse: 2.5781\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 2.9411 - mse: 2.9411\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 2.9050 - mse: 2.9050\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 2.9424 - mse: 2.9424\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 3.7134 - mse: 3.7134\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 3.8270 - mse: 3.8270\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 2.9756 - mse: 2.9756\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 2.8813 - mse: 2.8813\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 2.1268 - mse: 2.1268\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 3.7682 - mse: 3.7682\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, None, 100)         44400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 1)           101       \n",
      "=================================================================\n",
      "Total params: 44,501\n",
      "Trainable params: 44,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 28ms/step - loss: 0.7314 - mse: 0.7314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7313611507415771, 0.7313611507415771]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## bi is worse than normal performance\n",
    "model = bi_seq_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "australian-period",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 3s 49ms/step - loss: 18.6518 - mse: 18.6518\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 3.3098 - mse: 3.3098\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 3.1020 - mse: 3.1020\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 3.3478 - mse: 3.3478\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.8998 - mse: 2.8998\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.0524 - mse: 2.0524\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.4135 - mse: 2.4135\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 2.5419 - mse: 2.5419\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.0306 - mse: 2.0306\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 3.5899 - mse: 3.5899\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 2.3527 - mse: 2.3527\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 3.3782 - mse: 3.3782\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.6061 - mse: 2.6061\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2.0409 - mse: 2.0409\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2.1412 - mse: 2.1412\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2.6523 - mse: 2.6523\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 2.5828 - mse: 2.5828\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2.1753 - mse: 2.1753\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 4.3278 - mse: 4.3278\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2.5477 - mse: 2.5477\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.3390 - mse: 3.3390\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.2149 - mse: 2.2149\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2.4517 - mse: 2.4517\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 4.1700 - mse: 4.1700\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.0299 - mse: 3.0299\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 2.2682 - mse: 2.2682\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.6159 - mse: 2.6159\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 3.2719 - mse: 3.2719\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 3.3984 - mse: 3.3984\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 2.3916 - mse: 2.3916\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, None, 50)          22200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 1)           51        \n",
      "=================================================================\n",
      "Total params: 22,251\n",
      "Trainable params: 22,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6482 - mse: 0.6482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6482141613960266, 0.6482141613960266]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = stack_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stone-crowd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 12s 181ms/step - loss: 19.3969 - mse: 19.3969\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 2s 166ms/step - loss: 3.0059 - mse: 3.0059\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 2s 172ms/step - loss: 2.4847 - mse: 2.4847\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 2s 180ms/step - loss: 3.3939 - mse: 3.3939\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 2s 173ms/step - loss: 3.0596 - mse: 3.0596\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 2s 170ms/step - loss: 3.8863 - mse: 3.8863\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 2s 181ms/step - loss: 3.0822 - mse: 3.0822\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 2s 237ms/step - loss: 2.8699 - mse: 2.8699\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 2s 266ms/step - loss: 2.6428 - mse: 2.6428\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 2.3296 - mse: 2.3296\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 2.4883 - mse: 2.4883\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 3.0681 - mse: 3.0681\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 3.5540 - mse: 3.5540\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 2s 265ms/step - loss: 2.7255 - mse: 2.7255\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 2.9827 - mse: 2.9827\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 3.0454 - mse: 3.0454\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 2s 267ms/step - loss: 3.0451 - mse: 3.0451\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 3s 324ms/step - loss: 3.6081 - mse: 3.6081\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 3s 287ms/step - loss: 3.0203 - mse: 3.0203\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 2.9589 - mse: 2.9589\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 2.7661 - mse: 2.7661\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 2.4094 - mse: 2.4094\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 2s 166ms/step - loss: 4.1835 - mse: 4.1835\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 3.1693 - mse: 3.1693\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 1s 165ms/step - loss: 3.6228 - mse: 3.6228\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 1s 164ms/step - loss: 2.5004 - mse: 2.5004\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 2s 167ms/step - loss: 2.7571 - mse: 2.7571\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 2s 175ms/step - loss: 2.2469 - mse: 2.2469\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 2.6576 - mse: 2.6576\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 3.5638 - mse: 3.5638\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 2.1247 - mse: 2.1247\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 4.5046 - mse: 4.5046\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 3.4131 - mse: 3.4131\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 2.7211 - mse: 2.7211\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, None, 100)         44400     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 100)         60400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 1)           101       \n",
      "=================================================================\n",
      "Total params: 104,901\n",
      "Trainable params: 104,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff2285f5f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 2s 51ms/step - loss: 0.4936 - mse: 0.4936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4936085641384125, 0.4936085641384125]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bi_stack_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "molecular-emergency",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 5s 67ms/step - loss: 22.1451 - mse: 22.1451\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 2.8938 - mse: 2.8938\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 2.1290 - mse: 2.1290\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 2.7939 - mse: 2.7939\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 3.3690 - mse: 3.3690\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 2.6608 - mse: 2.6608\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 2.5488 - mse: 2.5488\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 2.1268 - mse: 2.1268\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 2.7385 - mse: 2.7385\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 2.5151 - mse: 2.5151\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 3.1930 - mse: 3.1930\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 2.7476 - mse: 2.7476\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 3.1129 - mse: 3.1129\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 2.1972 - mse: 2.1972\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 3.3875 - mse: 3.3875\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_3 (Bidirection (None, None, 100)         44400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 1)           101       \n",
      "=================================================================\n",
      "Total params: 44,501\n",
      "Trainable params: 44,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff23bce90d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 38ms/step - loss: 0.5263 - mse: 0.5263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5262715220451355, 0.5262715220451355]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bi_back_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "young-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "## needs to pass a sequence from first bi to second\n",
    "# model = bi_back_stack_lstm_model()\n",
    "# model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "# model.summary()\n",
    "# model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "connected-south",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 3s 71ms/step - loss: 21.8044 - mse: 21.8044\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 1s 51ms/step - loss: 3.6990 - mse: 3.6990\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 4.1096 - mse: 4.1096\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1.7513 - mse: 1.7513\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.1134 - mse: 2.1134\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 2.3779 - mse: 2.3779\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 2.2897 - mse: 2.2897\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1.9715 - mse: 1.9715\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 2.1338 - mse: 2.1338\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2.8771 - mse: 2.8771\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 2.8699 - mse: 2.8699\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2.9509 - mse: 2.9509\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, None, 50)          22200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, None, 1)           51        \n",
      "=================================================================\n",
      "Total params: 22,251\n",
      "Trainable params: 22,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff23ef159d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 21ms/step - loss: 0.5584 - mse: 0.5584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5583867430686951, 0.5583867430686951]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = stack_3_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "auburn-boating",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 3s 53ms/step - loss: 21.9634 - mse: 21.9634\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 11.4250 - mse: 11.4250\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 9.5048 - mse: 9.5048\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 9.9796 - mse: 9.9796\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 7.5560 - mse: 7.5560\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 7.8222 - mse: 7.8222\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 7.9343 - mse: 7.9343\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 7.6211 - mse: 7.6211\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 6.4610 - mse: 6.4610\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 7.2251 - mse: 7.2251\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 8.5354 - mse: 8.5354\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 6.4918 - mse: 6.4918\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 5.7239 - mse: 5.7239\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 5.2305 - mse: 5.2305\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 6.4562 - mse: 6.4562\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 4.8108 - mse: 4.8108\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 5.4272 - mse: 5.4272\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 5.3977 - mse: 5.3977\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 4.5864 - mse: 4.5864\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 4.0267 - mse: 4.0267\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 5.9233 - mse: 5.9233\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 5.9712 - mse: 5.9712\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 4.6083 - mse: 4.6083\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 4.6659 - mse: 4.6659\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3.8392 - mse: 3.8392\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 5.9936 - mse: 5.9936\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 4.8760 - mse: 4.8760\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 4.1224 - mse: 4.1224\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 3.9516 - mse: 3.9516\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 4.7903 - mse: 4.7903\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 4.6647 - mse: 4.6647\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 4.7170 - mse: 4.7170\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 4.5741 - mse: 4.5741\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 5.2858 - mse: 5.2858\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 4.6672 - mse: 4.6672\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.6094 - mse: 3.6094\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 4.7356 - mse: 4.7356\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 4.4809 - mse: 4.4809\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 4.1445 - mse: 4.1445\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 4.0014 - mse: 4.0014\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 3.5334 - mse: 3.5334\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 3.5151 - mse: 3.5151\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 3.9346 - mse: 3.9346\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 3.8114 - mse: 3.8114\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 3.9380 - mse: 3.9380\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 3.8407 - mse: 3.8407\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 4.0492 - mse: 4.0492\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 1s 53ms/step - loss: 4.7823 - mse: 4.7823\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 3.8114 - mse: 3.8114\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 50)                22200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 25,977\n",
      "Trainable params: 25,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff22ba92820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 19ms/step - loss: 0.7875 - mse: 0.7875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7875046730041504, 0.7875046730041504]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deep_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "neural-brazil",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 3s 46ms/step - loss: 38.2980 - mse: 38.2980\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 5.6113 - mse: 5.6113\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2.2700 - mse: 2.2700\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 3.7361 - mse: 3.7361\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.6994 - mse: 2.6994\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2.8685 - mse: 2.8685\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 2.7528 - mse: 2.7528\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.0685 - mse: 3.0685\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.4771 - mse: 3.4771\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2.6080 - mse: 2.6080\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 3.8709 - mse: 3.8709\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 2.9913 - mse: 2.9913\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.6377 - mse: 2.6377\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3.5122 - mse: 3.5122\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3.6412 - mse: 3.6412\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3.7261 - mse: 3.7261\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 2.1305 - mse: 2.1305\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2.7383 - mse: 2.7383\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.6609 - mse: 2.6609\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2.5587 - mse: 2.5587\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3.1598 - mse: 3.1598\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 2.0708 - mse: 2.0708\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 2.7904 - mse: 2.7904\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 50)                22200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 23,865\n",
      "Trainable params: 23,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff227182b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4828 - mse: 0.4828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4827669858932495, 0.4827669858932495]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lstm_dense_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "breeding-addition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 4s 51ms/step - loss: 48.9082 - mse: 48.9082\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 27.3246 - mse: 27.3246\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 16.2593 - mse: 16.2593\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 10.1265 - mse: 10.1265\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 6.8159 - mse: 6.8159\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 7.9272 - mse: 7.9272\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 6.8193 - mse: 6.8193\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 8.8974 - mse: 8.8974\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 6.8820 - mse: 6.8820\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 6.4671 - mse: 6.4671\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 6.8096 - mse: 6.8096\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 7.2055 - mse: 7.2055\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 4.3625 - mse: 4.3625\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 3.6604 - mse: 3.6604\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 3.6781 - mse: 3.6781: 0s - loss: 3.9973 - mse\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.8198 - mse: 2.8198\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 2.2084 - mse: 2.2084\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 3.1204 - mse: 3.1204\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 2.7056 - mse: 2.7056\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 2.5128 - mse: 2.5128\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 2.2543 - mse: 2.2543\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2.5358 - mse: 2.5358\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.5444 - mse: 2.5444\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 2.2425 - mse: 2.2425\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 2.9938 - mse: 2.9938\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 2.3531 - mse: 2.3531\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2.1576 - mse: 2.1576\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2.9922 - mse: 2.9922\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2.0841 - mse: 2.0841\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1.9850 - mse: 1.9850\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1.5389 - mse: 1.5389\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1.6190 - mse: 1.6190\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 1.3219 - mse: 1.3219\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 2.3042 - mse: 2.3042\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 2.3197 - mse: 2.3197\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 3.5825 - mse: 3.5825\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 2.1495 - mse: 2.1495\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2.2328 - mse: 2.2328\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1.7008 - mse: 1.7008\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1.4186 - mse: 1.4186\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1.6967 - mse: 1.6967\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1.6622 - mse: 1.6622\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1.6071 - mse: 1.6071\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1.3186 - mse: 1.3186\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1.5626 - mse: 1.5626\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1.0716 - mse: 1.0716\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1.2282 - mse: 1.2282\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 1.4863 - mse: 1.4863\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.9312 - mse: 0.9312\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.8511 - mse: 0.8511\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1.9364 - mse: 1.9364\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 3.7656 - mse: 3.7656\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1.7146 - mse: 1.7146\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 1.3969 - mse: 1.3969\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1.9378 - mse: 1.9378\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.4055 - mse: 2.4055\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1.2730 - mse: 1.2730\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1.6837 - mse: 1.6837\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.9160 - mse: 0.9160\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1.3301 - mse: 1.3301\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 50)                22200     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 24,193\n",
      "Trainable params: 24,029\n",
      "Non-trainable params: 164\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff22866c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 18ms/step - loss: 1.7239 - mse: 1.7239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.723872184753418, 1.723872184753418]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = batch_norm_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "minus-medication",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 4s 79ms/step - loss: 10.3177 - mse: 10.3177\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.8220 - mse: 2.8220\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 2.4047 - mse: 2.4047\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 1.6170 - mse: 1.6170\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 2.8918 - mse: 2.8918\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 3.1977 - mse: 3.1977\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 2.9403 - mse: 2.9403\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2.1939 - mse: 2.1939\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 2.0440 - mse: 2.0440\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 2.4830 - mse: 2.4830\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 3.1654 - mse: 3.1654\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2.5494 - mse: 2.5494\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 1.9271 - mse: 1.9271\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 2.5209 - mse: 2.5209\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 2.1084 - mse: 2.1084\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 3.7036 - mse: 3.7036\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 2s 148ms/step - loss: 2.7862 - mse: 2.7862\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 2.6129 - mse: 2.6129\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 2.3793 - mse: 2.3793\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 50)                22200     \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 50)                100       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 32)                64        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 24,029\n",
      "Trainable params: 24,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff2285f58b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 18ms/step - loss: 0.6986 - mse: 0.6986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6985833048820496, 0.6985833048820496]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = layer_norm_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "convertible-times",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 4s 71ms/step - loss: 33.0832 - mse: 33.0832\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 23.9075 - mse: 23.9075\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 17.3381 - mse: 17.3381\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 10.6094 - mse: 10.6094\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 7.7551 - mse: 7.7551\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 7.3762 - mse: 7.3762\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 7.0882 - mse: 7.0882\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 7.5270 - mse: 7.5270\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 7.3039 - mse: 7.3039\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 6.7746 - mse: 6.7746\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 6.9167 - mse: 6.9167\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 6.4798 - mse: 6.4798\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 5.5369 - mse: 5.5369\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 6.8788 - mse: 6.8788\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 5.9715 - mse: 5.9715\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 5.5519 - mse: 5.5519\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 5.2320 - mse: 5.2320\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 1s 77ms/step - loss: 5.9874 - mse: 5.9874\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 5.4053 - mse: 5.4053\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 5.6157 - mse: 5.6157\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 6.0029 - mse: 6.0029\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 5.0854 - mse: 5.0854\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 4.9621 - mse: 4.9621\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 5.9687 - mse: 5.9687\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 4.8657 - mse: 4.8657\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 5.4629 - mse: 5.4629\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 5.0604 - mse: 5.0604\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 5.1406 - mse: 5.1406\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 5.0605 - mse: 5.0605\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 5.2029 - mse: 5.2029\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 5.3069 - mse: 5.3069\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 4.7463 - mse: 4.7463\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 5.4030 - mse: 5.4030\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 4.9242 - mse: 4.9242\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 4.6149 - mse: 4.6149\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 4.4336 - mse: 4.4336\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 4.6764 - mse: 4.6764\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 4.3460 - mse: 4.3460\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 5.8336 - mse: 5.8336\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 4.7102 - mse: 4.7102\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 4.5935 - mse: 4.5935\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 5.0034 - mse: 5.0034\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 4.4774 - mse: 4.4774\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 4.9006 - mse: 4.9006\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 4.9336 - mse: 4.9336\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 4.6452 - mse: 4.6452\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 4.0470 - mse: 4.0470\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 4.2096 - mse: 4.2096\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 3.9751 - mse: 3.9751\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 4.4921 - mse: 4.4921\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 5.2588 - mse: 5.2588\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 4.5025 - mse: 4.5025\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 4.4895 - mse: 4.4895\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 4.0066 - mse: 4.0066\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 4.8724 - mse: 4.8724\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 4.3237 - mse: 4.3237\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 4.6586 - mse: 4.6586\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 4.6954 - mse: 4.6954\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 4.2554 - mse: 4.2554\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 4.1516 - mse: 4.1516\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 4.4676 - mse: 4.4676\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 4.9423 - mse: 4.9423\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 4.2347 - mse: 4.2347\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 3.6748 - mse: 3.6748\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 3.3752 - mse: 3.3752\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 3.9353 - mse: 3.9353\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 4.5541 - mse: 4.5541\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 1s 52ms/step - loss: 3.7650 - mse: 3.7650\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 4.5431 - mse: 4.5431\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 3.7563 - mse: 3.7563\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 4.9402 - mse: 4.9402\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 4.1240 - mse: 4.1240\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 3.7783 - mse: 3.7783\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 4.2374 - mse: 4.2374\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 3.7557 - mse: 3.7557\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 3.7349 - mse: 3.7349\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 3.8288 - mse: 3.8288\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 4.0683 - mse: 4.0683\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 3.9622 - mse: 3.9622\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 3.5704 - mse: 3.5704\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 3.5967 - mse: 3.5967\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 4.5332 - mse: 4.5332\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 3.2763 - mse: 3.2763\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 4.4208 - mse: 4.4208\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 3.1123 - mse: 3.1123\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 4.0226 - mse: 4.0226\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 4.1862 - mse: 4.1862\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 57ms/step - loss: 3.2458 - mse: 3.2458\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 4.4798 - mse: 4.4798\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 4.5000 - mse: 4.5000\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 4.1194 - mse: 4.1194\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 3.6880 - mse: 3.6880\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 3.9143 - mse: 3.9143\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 1s 55ms/step - loss: 3.7892 - mse: 3.7892\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 4.5635 - mse: 4.5635\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 50)                22200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 24,193\n",
      "Trainable params: 24,029\n",
      "Non-trainable params: 164\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff244687700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 18ms/step - loss: 3.0545 - mse: 3.0545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.054544448852539, 3.054544448852539]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## much better with drop out than without. \n",
    "model = batch_norm_drop_lstm_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pediatric-western",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 4s 44ms/step - loss: 4.8552 - mse: 4.8552\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 5.0709 - mse: 5.0709\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 3.0959 - mse: 3.0959\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 2.9718 - mse: 2.9718\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2.0556 - mse: 2.0556\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2.4908 - mse: 2.4908\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 3.4216 - mse: 3.4216\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.5504 - mse: 2.5504\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 2.5444 - mse: 2.5444\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.3805 - mse: 3.3805\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.1671 - mse: 3.1671\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 1s 73ms/step - loss: 2.5945 - mse: 2.5945\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2.4272 - mse: 2.4272\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 3.1431 - mse: 3.1431\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 2.6997 - mse: 2.6997: 0s - loss: 2.3811 - mse\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1.8927 - mse: 1.8927\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 3.0679 - mse: 3.0679\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2.7577 - mse: 2.7577\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 2.4603 - mse: 2.4603\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2.2814 - mse: 2.2814\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 2.2609 - mse: 2.2609\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 2.4440 - mse: 2.4440\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 50)                16800     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 16,851\n",
      "Trainable params: 16,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff22a759280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 20ms/step - loss: 0.5256 - mse: 0.5256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5255981087684631, 0.5255981087684631]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gru_model()\n",
    "model.fit(data_gen_train, epochs=100, callbacks=[early_stop])\n",
    "model.summary()\n",
    "model.evaluate(data_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-humanity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-brazil",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
