{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competitive-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run following in termminal (or in notebook) if needed to get packages to work\n",
    "# !conda create -n tensorflow\n",
    "# !source activate tensorflow\n",
    "# !pip install jupyter notebook\n",
    "# !jupyter-notebook\n",
    "# !which pip\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install sklearn pandas numpy seaborn\n",
    "\n",
    "## data split custom tool\n",
    "from timeseries_train_test_split import TimeseriesTestTrainSplit as ts\n",
    "##standard tools\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "##preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "## model selection and building\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import explained_variance_score as evs\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import median_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "##models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet, LassoLars, BayesianRidge, ARDRegression, Perceptron, PassiveAggressiveRegressor, TheilSenRegressor, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor, StackingRegressor, VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "leading-protection",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/stocks_df_2021-02-26.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-96b6b6b50567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# def run():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstock_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'GSIT'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries_test_train_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/swe/finance_ml_analysis/notebooks_exploration/timeseries_train_test_split.py\u001b[0m in \u001b[0;36mtimeseries_test_train_split\u001b[0;34m(cls, stock_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimeseries_test_train_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GSIT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mstocks_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/swe/finance_ml_analysis/notebooks_exploration/timeseries_train_test_split.py\u001b[0m in \u001b[0;36mload_df\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mstocks_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/stocks_df_{}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mstocks_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstocks_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/stocks_df_2021-02-26.pickle'"
     ]
    }
   ],
   "source": [
    "# def run():\n",
    "stock_name = 'GSIT'\n",
    "X_train, y_train, X_test, y_test = ts.timeseries_test_train_split(stock_name)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = FeatureUnion([('scaler', MinMaxScaler()), ('norm', Normalizer())])\n",
    "pipe = Pipeline([('preprocess', StandardScaler()), ('predictor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model \n",
    "def lstm_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model \n",
    "keras_base = KerasRegressor(build_fn = baseline_model, nb_epoch=100, batch_size=5, verbose=1)\n",
    "keras_lstm = KerasRegressor(build_fn = lstm_model, nb_epoch=100, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = {'predictor': [LinearRegression()]}\n",
    "svr_grid = {\n",
    "    'predictor': [SVR()],\n",
    "    'predictor__kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "d_tree_grid = {\n",
    "    'predictor': [DecisionTreeRegressor()],\n",
    "    'predictor__criterion': ['mse', 'friedman_mse', 'mae', 'poisson']  \n",
    "}\n",
    "mlp_grid = {\n",
    "    'predictor': [MLPRegressor()],\n",
    "    'predictor__learning_rate_init': [0.001],\n",
    "    'predictor__random_state': [1],\n",
    "    'predictor__max_iter': [400],\n",
    "    'predictor__activation': ['relu','logistic'], ##'tanh',\n",
    "    'predictor__hidden_layer_sizes': [(100,),(125,)], ## ,(50,)\n",
    "    'predictor__alpha': [10**-x for x in range(1, 7)]\n",
    "}\n",
    "rfr_grid = {'predictor': [RandomForestRegressor()]  }\n",
    "gbr_grid = {\n",
    "    'predictor': [GradientBoostingRegressor()],\n",
    "    'predictor__loss': ['ls', 'lad', 'huber', 'quantile']\n",
    "}\n",
    "etr_grid = {'predictor': [ExtraTreesRegressor()]}\n",
    "abr_grid = {'predictor': [AdaBoostRegressor()]}\n",
    "sgdr_grid = {'predictor': [SGDRegressor()]}\n",
    "ridge_grid = {'predictor': [Ridge()]}\n",
    "lasso_grid = {'predictor': [Lasso()]}\n",
    "enet_grid = {'predictor': [ElasticNet()]}\n",
    "lars_lasso_grid = {'predictor': [LassoLars()]}\n",
    "br_grid = {'predictor': [BayesianRidge()]}\n",
    "adrr_grid = {'predictor': [ARDRegression()]}\n",
    "percep_grid = {'predictor': [Perceptron()]}\n",
    "par_grid = {'predictor': [PassiveAggressiveRegressor()]}\n",
    "tsr_grid = {'predictor': [TheilSenRegressor()]}\n",
    "hbr_grid = {'predictor': [HuberRegressor()]}\n",
    "keras_base_grid = {'predictor': [keras_base]}\n",
    "keras_lstm_grid = {'predictor': [keras_lstm]}\n",
    "param_grid = [\n",
    "    {**lr_grid},\n",
    "    {**mlp_grid}, ##takes a long time\n",
    "    {**svr_grid},\n",
    "    {**d_tree_grid},\n",
    "    {**rfr_grid},\n",
    "    {**gbr_grid},\n",
    "    {**etr_grid},\n",
    "    {**abr_grid},\n",
    "    {**sgdr_grid}, ##near competitor to linreg\n",
    "    {**ridge_grid}, ##near competitor to linreg\n",
    "    {**lasso_grid},\n",
    "    {**enet_grid},\n",
    "    {**lars_lasso_grid},\n",
    "    {**br_grid},\n",
    "    {**adrr_grid},\n",
    "    {**percep_grid}, ##not working\n",
    "    {**par_grid},\n",
    "    {**tsr_grid}, ##better than linear; and takes a while\n",
    "    {**hbr_grid}\n",
    "    {**keras_base_grid}\n",
    "    {**keras_lstm_grid}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "grid = GridSearchCV(pipe, param_grid, verbose=4, cv = 3, scoring='neg_median_absolute_error')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_est = grid.best_estimator_\n",
    "y_pred = pipe.predict(X_test)\n",
    "grid_pred = grid_est.predict(X_test)\n",
    "grid.score(X_test, y_test)\n",
    "print(grid.best_params_)\n",
    "print('scores in ', grid.get_scorer(),' : grid', grid_est.score(X_test, y_test), 'linreg', pipe.score(X_test, y_test))\n",
    "print(grid.scorer_)\n",
    "print('median_absolute_error as mae;','explained_variance_score as evs;','mean_absolute_percentage_error as mape;')\n",
    "print('linreg', mae(y_test, y_pred), evs(y_test, y_pred), mape(y_test, y_pred))\n",
    "print('grid', mae(y_test, grid_pred), evs(y_test, grid_pred), mape(y_test, grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i in range(len(y_test))]\n",
    "plt.scatter(index, y_test, 'b')\n",
    "plt.plot(index, grid_pred, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(index, y_test)\n",
    "plt.plot(index, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-matthew",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
