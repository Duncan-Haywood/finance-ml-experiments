{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader\n",
    "import yaml\n",
    "import datetime\n",
    "import math\n",
    "from time import sleep\n",
    "# !pwd\n",
    "with open('../../alpha_key.yml', 'r') as f:\n",
    "    ALPHA_API_KEY = yaml.safe_load(f)['alpha_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickers = ['ARW','OBNK','UEIC','FERG']\n",
    "tickers += ['SPUC','CPRI','PDEX','TSOC','KR']\n",
    "tickers += ['CNO','CXW', 'NVDA','AAPL']\n",
    "tickers += ['AMZN','TSLA','ADXS','ALVR']\n",
    "tickers += ['INTC','NFLX','GOOG','BABA','CRM']\n",
    "tickers += ['CSCO','GSX','AMD','YELP']\n",
    "def format_dates(daily_stocks_data):\n",
    "    df = daily_stocks_data.copy() \n",
    "    df['date']=df.index\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "def concat_stocks(dfs, keys):\n",
    "    cat_df = pd.concat(dfs, axis='columns', keys=keys)\n",
    "    return cat_df\n",
    "def add_percent_change(df, metric):\n",
    "    percents = df[metric].pct_change()\n",
    "    df[f'{metric}_percent_change']=percents\n",
    "    return df\n",
    "def add_percent_changes(df, metrics=None):\n",
    "    if metrics is not None:\n",
    "        for metric in metrics:\n",
    "            df = add_percent_change(df,metric)\n",
    "    else:\n",
    "        for metric in df.columns:\n",
    "            df = add_percent_change(df,metric)\n",
    "    return df\n",
    "def add_weekly_cat(df):\n",
    "    day_cos, day_sin = list(), list()\n",
    "    for date in df.index:\n",
    "        day = datetime.datetime.strptime(date, '%Y-%m-%d').weekday()\n",
    "        radians = 2*math.pi*day/6\n",
    "        day_cos.append(math.cos(radians))\n",
    "        day_sin.append(math.sin(radians))\n",
    "    df['week_cos'] = day_cos\n",
    "    df['week_sin'] = day_sin\n",
    "    return df\n",
    "def add_yearly_cat(df):\n",
    "    day_cos, day_sin = list(), list()\n",
    "    for date in df.index:\n",
    "        day = datetime.datetime.strptime(date, '%Y-%m-%d').timetuple().tm_yday\n",
    "        radians = 2*math.pi*day/365\n",
    "        day_cos.append(math.cos(radians))\n",
    "        day_sin.append(math.sin(radians))\n",
    "    df['year_cos'] = day_cos\n",
    "    df['year_sin'] = day_sin\n",
    "    return df\n",
    "def add_stats(df, lengths, metrics=None):\n",
    "    if metrics is not None:\n",
    "        for metric in metrics:\n",
    "            df = add_metric_stats(df, lengths, metric)\n",
    "    else:\n",
    "        for metric in [m for m in df.columns]:\n",
    "            df = add_metric_stats(df, lengths, metric)\n",
    "    return df\n",
    "def add_metric_stats(df, lengths, metric):\n",
    "    for length in lengths:\n",
    "        win = df[metric].rolling(length, min_periods=1)\n",
    "        df[f'{metric}_{length}_mean'] = win.mean()\n",
    "        df[f'{metric}_{length}_median'] = win.median()\n",
    "        df[f'{metric}_{length}_std'] = win.std()\n",
    "        df[f'{metric}_{length}_skew'] = win.skew()\n",
    "        df[f'{metric}_{length}_quantile_5'] = win.quantile(0.05)\n",
    "        df[f'{metric}_{length}_quantile_95'] = win.quantile(0.95)\n",
    "        df[f'{metric}_{length}_quantile_10'] = win.quantile(0.10)\n",
    "        df[f'{metric}_{length}_quantile_90'] = win.quantile(0.90)\n",
    "        df[f'{metric}_{length}_high'] = win.max()\n",
    "        df[f'{metric}_{length}_low'] = win.min()\n",
    "        df[f'{metric}_{length}_spread'] = df[f'{metric}_{length}_high'].subtract(df[f'{metric}_{length}_low'])\n",
    "    return df\n",
    "\n",
    "def data_stats_to_file(tickers):\n",
    "    daily_stocks_data_raw_list = read_data_from_file(tickers)\n",
    "    i=0\n",
    "    for df in daily_stocks_data_raw_list:\n",
    "        ticker = tickers[i]\n",
    "        i+=1\n",
    "        try:\n",
    "            pd.read_pickle(f'./{ticker}_daily_stats.pkl')\n",
    "        except:\n",
    "            df.pipe(add_stats, lengths=[10,50,91,182,274,365], metrics=['open','close','high','low','volume']).pipe(add_percent_changes).pipe(add_weekly_cat).pipe(add_yearly_cat).to_pickle(f'./{ticker}_daily_stats.pkl')\n",
    "        display(f'{ticker} done')\n",
    "def combine_to_file(tickers):   \n",
    "    daily_stocks_data_list = [pd.from_pickle(f'./{ticker}_daily_stats.pkl') for ticker in tickers]\n",
    "    daily_stocks_data = pd.concat(daily_stocks_data_list, axis='columns', keys=tickers)\n",
    "    daily_stocks_data.to_pickle(f'./{tickers}_daily.pkl')\n",
    "\n",
    "def read_data(tickers):\n",
    "    daily_stocks_data_raw_list = []\n",
    "    for i in range(5,len(tickers),5):\n",
    "        daily_stocks_data_raw_list += [pandas_datareader.av.time_series.AVTimeSeriesReader(symbols=ticker, api_key=ALPHA_API_KEY, function='TIME_SERIES_DAILY').read() for ticker in tickers[i-5:i]]\n",
    "        sleep(61)\n",
    "    daily_stocks_data_raw_list += [pandas_datareader.av.time_series.AVTimeSeriesReader(symbols=ticker, api_key=ALPHA_API_KEY, function='TIME_SERIES_DAILY').read() for ticker in tickers[-len(tickers)%5:len(tickers)]]\n",
    "    return daily_stocks_data_raw_list\n",
    "def read_data_to_file(tickers):\n",
    "    i = 1\n",
    "    for ticker in tickers:      \n",
    "        try:\n",
    "            pd.read_pickle(f'./{ticker}_daily_raw.pkl')\n",
    "        except:\n",
    "            df = pandas_datareader.av.time_series.AVTimeSeriesReader(symbols=ticker, api_key=ALPHA_API_KEY, function='TIME_SERIES_DAILY').read()\n",
    "            df.to_pickle(f'./{ticker}_daily_raw.pkl')\n",
    "            i+=1\n",
    "            if (i)%5==0:\n",
    "                sleep(61)\n",
    "        display(f'{ticker} done')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARW done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'OBNK done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'UEIC done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'FERG done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'SPUC done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CPRI done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'PDEX done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TSOC done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'KR done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CNO done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CXW done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NVDA done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AAPL done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AMZN done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TSLA done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ADXS done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ALVR done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'INTC done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NFLX done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'GOOG done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'BABA done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CRM done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CSCO done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'GSX done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AMD done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'YELP done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'adding stats'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ARW done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'OBNK done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'UEIC done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'FERG done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'SPUC done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CPRI done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'PDEX done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TSOC done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'KR done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CNO done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CXW done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NVDA done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AAPL done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AMZN done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TSLA done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ADXS done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ALVR done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'INTC done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'NFLX done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'GOOG done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'BABA done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CRM done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CSCO done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'GSX done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AMD done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'YELP done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read_to_file_data(tickers)\n",
    "read_data_to_file(tickers)\n",
    "display('adding stats')\n",
    "data_stats_to_file(tickers)\n",
    "\n",
    "# daily_stocks_data = pd.read_pickle(f'./{tickers}_daily.pkl')\n",
    "# display([col for col in daily_stocks_data.columns])\n",
    "# display(daily_stocks_data.columns)\n",
    "# display(daily_stocks_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras for keras manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def to_ts_df(daily_stocks_data, lookback, metric):\n",
    "#     ## column names\n",
    "#     columns = list()\n",
    "#     for i in range(lookback):\n",
    "#         columns.append(f'{metric}_{i}')\n",
    "#     columns.append(f'{metric}_target')\n",
    "#     df = pd.DataFrame(columns=columns)\n",
    "#     ## columns\n",
    "#     data = daily_stocks_data[metric].to_numpy()\n",
    "#     for index, col in enumerate(df.columns):\n",
    "#         df[col] = data[index:len(data)-lookback+index]\n",
    "#     ## dates index\n",
    "#     dates = daily_stocks_data.date.to_numpy()[:-lookback]\n",
    "#     df.insert(0, 'dates', dates)\n",
    "#     df.dropna(axis='index', inplace=True)\n",
    "#     return df\n",
    "# def to_ts(df, metric, lookback):\n",
    "#     data, targets = list(), list()\n",
    "#     for i in range(lookback,len(df.index)):\n",
    "#         data.append(df.iloc[i-lookback:i,:].values) ## first four metrics\n",
    "#         targets.append(df[metric].to_list()[i])\n",
    "#     data = np.array(data)\n",
    "#     targets = np.array(targets)\n",
    "#     return data, targets\n",
    "# def min_max_scale(col):\n",
    "#     scaled = col.subtract(col.min()).divide(col.max()-col.min())\n",
    "#     return scaled\n",
    "# def multi_stock_ts_split(df,tickers): ## could be sped up \n",
    "#     data_tr, data_te, targets_tr, targets_te = [],[],[],[]\n",
    "#     for ticker in tickers:\n",
    "#         data, targets = to_ts(df[ticker].dropna(), 'low', lookback) ## drops nan for each stock\n",
    "#         x = train_test_split(data, targets, shuffle=False)\n",
    "#         data_tr.append(x[0])\n",
    "#         data_te.append(x[1])\n",
    "#         targets_tr.append(x[2]) \n",
    "#         targets_te.append(x[3])    \n",
    "#     return np.concatenate(data_tr), np.concatenate(data_te), np.concatenate(targets_tr), np.concatenate(targets_te)\n",
    "# df = pd.read_pickle(f\"./{tickers}_daily.pkl\")\n",
    "# df = df.apply(min_max_scale)\n",
    "# features = len(df.columns)\n",
    "# display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
