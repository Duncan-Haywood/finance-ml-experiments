{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_datareader\n",
    "import boto3\n",
    "import base64\n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import display\n",
    "import pandas_datareader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import os\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name AmazonSageMaker-ExecutionRole-20210310T221946 to get Role path.\n",
      "Assuming role was created in SageMaker AWS console, as the name contains `AmazonSageMaker-ExecutionRole`. Defaulting to Role ARN with service-role in path. If this Role ARN is incorrect, please add IAM read permissions to your role or supply the Role Arn directly.\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'stock-data-raw'\n",
    "tickers_url = 'http://ftp.nasdaqtrader.com/dynamic/SymDir/nasdaqlisted.txt'\n",
    "# tickers = ['AAPL', 'NVDA'] ## to be changed to the entire list at http://ftp.nasdaqtrader.com/dynamic/SymDir/nasdaqlisted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AACG',\n",
       " 'AACQ',\n",
       " 'AACQU',\n",
       " 'AACQW',\n",
       " 'AAL',\n",
       " 'AAME',\n",
       " 'AAOI',\n",
       " 'AAON',\n",
       " 'AAPL',\n",
       " 'AAWW',\n",
       " 'AAXJ',\n",
       " 'ABCB',\n",
       " 'ABCL',\n",
       " 'ABCM',\n",
       " 'ABEO',\n",
       " 'ABGI',\n",
       " 'ABIO',\n",
       " 'ABMD',\n",
       " 'ABNB',\n",
       " 'ABST']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## to do for massive data base; keeping small for now. \n",
    "def get_all_tickers(tickers_url):\n",
    "    text = requests.get(tickers_url).text\n",
    "    with open('temp.csv', 'w') as f:\n",
    "        f.write(text)\n",
    "    df = pd.read_csv('temp.csv', delimiter='|')\n",
    "    tickers = df.Symbol.tolist()\n",
    "    return tickers\n",
    "tickers = get_all_tickers(tickers_url)[:20]\n",
    "display(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secret():\n",
    "    secret_name = \"alpha_vantage\"\n",
    "    region_name = \"us-east-2\"\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except Exception as e:\n",
    "        display(e)\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            secret = get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            secret = base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "    return secret   \n",
    "\n",
    "def filter_complete_tickers(tickers, bucket, prefix):\n",
    "    file_names = sess.list_s3_files(bucket, prefix)\n",
    "    new = []\n",
    "    for ticker in tickers:\n",
    "        ticker_file_name = os.path.join(prefix, f'{ticker}_daily_raw.parquet')\n",
    "        if ticker_file_name not in file_names:\n",
    "            new.append(ticker)\n",
    "    return new\n",
    "                        \n",
    "def read_data_to_s3(tickers, ALPHA_API_KEY, bucket, prefix):\n",
    "    tickers = filter_complete_tickers(tickers, bucket, prefix)\n",
    "    i = 0\n",
    "    for ticker in tickers:      \n",
    "        try: ## TODO: switch from error handling to simple check if exists; no pull of data\n",
    "            pandas_datareader.av.time_series.AVTimeSeriesReader(symbols=ticker, api_key=ALPHA_API_KEY, function='TIME_SERIES_DAILY').read().to_parquet('temp.parquet')\n",
    "            boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, f'{ticker}_daily_raw.parquet')).upload_file('temp.parquet')\n",
    "            ## logic for api waiting\n",
    "            i+=1\n",
    "            if i%5==0: ## for 5 requests per minute limit on api\n",
    "                sleep(61)\n",
    "            if i%500==0:\n",
    "                sleep(24*60*60+1) ## 1 day for 500 requests per day limit on api\n",
    "#             pd.read_pickle(f'./{ticker}_daily_raw.pkl')\n",
    "        except Exception as e:\n",
    "            display(e)\n",
    "            break\n",
    "        display(f'{ticker} done')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALPHA_API_KEY = get_secret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAXJ done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ABCB done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ABCL done'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pandas_datareader._utils.RemoteDataError(\" Their was an issue from the data vendor side, here is their response: {'Note': 'Thank you for using Alpha Vantage! Our standard API call frequency is 5 calls per minute and 500 calls per day. Please visit https://www.alphavantage.co/premium/ if you would like to target a higher API call frequency.'}\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_data_to_s3(tickers, ALPHA_API_KEY, bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stock-data-raw/AACG_daily_raw.parquet',\n",
       " 'stock-data-raw/AACQU_daily_raw.parquet',\n",
       " 'stock-data-raw/AACQW_daily_raw.parquet',\n",
       " 'stock-data-raw/AACQ_daily_raw.parquet',\n",
       " 'stock-data-raw/AAL_daily_raw.parquet',\n",
       " 'stock-data-raw/AAME_daily_raw.parquet',\n",
       " 'stock-data-raw/AAOI_daily_raw.parquet',\n",
       " 'stock-data-raw/AAON_daily_raw.parquet',\n",
       " 'stock-data-raw/AAPL_daily_raw.parquet',\n",
       " 'stock-data-raw/AAWW_daily_raw.parquet',\n",
       " 'stock-data-raw/NVDA_daily_raw.parquet']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## test whether upload worked\n",
    "display(sess.list_s3_files(bucket, prefix))\n",
    "# sess.download_data('./test.parquet',bucket, prefix)\n",
    "\n",
    "# df = pd.read_parquet('test.parquet')\n",
    "\n",
    "# diplay(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
