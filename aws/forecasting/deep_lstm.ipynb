{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_datareader keras seaborn\n",
    "# !conda install -y -c conda-forge fbprophet\n",
    "# !pip install pydot graphviz\n",
    "import boto3\n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import display\n",
    "import pandas_datareader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Attention\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AAPL']\n",
    "metric = 'low'\n",
    "pc_metric = f'{metric}_percent_change'\n",
    "norm_metric = f'{pc_metric}_norm'\n",
    "lookback=100\n",
    "def get_secret():\n",
    "    secret_name = \"alpha_vantage\"\n",
    "    region_name = \"us-east-2\"\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        display(e)\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            secret = get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            secret = base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "    return secret   \n",
    "def format_dates(daily_stocks_data):\n",
    "    df = daily_stocks_data.copy() \n",
    "    df['date']=df.index\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "def add_percent_change(daily_stocks_data, metric):\n",
    "    percents = list()\n",
    "    for index, row in daily_stocks_data.iterrows():\n",
    "        old = row[metric]\n",
    "        try:\n",
    "            new = daily_stocks_data.iloc[index + 1][metric]\n",
    "        except Exception as e:\n",
    "            percents.append(np.nan) ## no next value, so this is undefined\n",
    "            continue\n",
    "        percents.append((new-old)/new)\n",
    "    cp_df = daily_stocks_data.copy()\n",
    "    cp_df[f'{metric}_percent_change']=percents\n",
    "    return cp_df\n",
    "def add_norm(df, label):\n",
    "    arr = np.array([x*1000 for x in df[label].to_numpy()]).reshape(-1, 1)\n",
    "#     norm = normalize(arr, norm='l1')\n",
    "    norm = arr\n",
    "    new_df = df.copy()\n",
    "    new_df[f'{label}_norm'] = norm\n",
    "    return new_df\n",
    "def to_ts_df(daily_stocks_data, lookback, metric):\n",
    "    ## column names\n",
    "    columns = list()\n",
    "    for i in range(lookback):\n",
    "        columns.append(f'{metric}_{i}')\n",
    "    columns.append(f'{metric}_target')\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    ## columns\n",
    "    data = daily_stocks_data[metric].to_numpy()\n",
    "    for index, col in enumerate(df.columns):\n",
    "        df[col] = data[index:len(data)-lookback+index]\n",
    "    ## dates index\n",
    "    dates = daily_stocks_data.date.to_numpy()[:-lookback]\n",
    "    df.insert(0, 'date', dates)\n",
    "    return df\n",
    "def to_ts(ts_df):\n",
    "    data = list()\n",
    "    targets = list()\n",
    "    for index, row in ts_df.iloc[:,1:].iterrows():\n",
    "        rnp = row.to_numpy()\n",
    "        data.append([[x] for x in rnp[:-1]])\n",
    "        targets.append(rnp[-1])\n",
    "    data = np.array(data)\n",
    "    targets = np.array(targets)\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA_API_KEY = get_secret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_stocks_data_raw = pandas_datareader.av.time_series.AVTimeSeriesReader(symbols=tickers, api_key=ALPHA_API_KEY, function='TIME_SERIES_DAILY').read()\n",
    "daily_stocks_data = format_dates(daily_stocks_data_raw) \n",
    "daily_stocks_data = add_percent_change(daily_stocks_data, metric)\n",
    "daily_stocks_data[daily_stocks_data[pc_metric].isnull()] = 0\n",
    "daily_stocks_data = add_norm(daily_stocks_data, pc_metric)\n",
    "ts_df = to_ts_df(daily_stocks_data, lookback, pc_metric)\n",
    "data, targets = to_ts(ts_df)\n",
    "display(daily_stocks_data)\n",
    "display(ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(None,1)))\n",
    "#     model.add(LSTM(12, return_sequences=True))\n",
    "#     model.add(LSTM(12, return_sequences=True))\n",
    "#     model.add(LSTM(6, return_sequences=True))\n",
    "    model.add(LSTM(6, return_sequences=True))\n",
    "    model.add(LSTM(2, return_sequences=True))\n",
    "    model.add(LSTM(1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', metrics=['mse','mape'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, None, 2)           32        \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, None, 2)           40        \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, None, 2)           40        \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, None, 2)           40        \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, None, 2)           40        \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 1)                 16        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 210\n",
      "Trainable params: 210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = deep_lstm()\n",
    "model.summary()\n",
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 58/110 [==============>...............] - ETA: 15s - loss: 0.0177 - mse: 0.0179 - mape: 9661.1162"
     ]
    }
   ],
   "source": [
    "early = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "model.fit(x=data, y=targets, batch_size=36, validation_split=0.2, epochs=100, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
